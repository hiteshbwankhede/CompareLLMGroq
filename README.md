---
title: LLM Model Comparator
emoji: 🔍
colorFrom: green
colorTo: blue
sdk: streamlit
sdk_version: 1.35.0
app_file: app.py
pinned: false
---

# 🔍 LLM Model Comparator

Compare outputs from **two different LLMs** on the same prompt using:

- 🧠 LangChain with `ChatGroq`
- 🌐 Streamlit UI
- 📊 LangSmith for tracing

## 💡 Features

- Prompt input
- Side-by-side LLM comparison
- Adjustable temperature
- Model selector from Groq (`mixtral`, `gemma`, `llama3`)